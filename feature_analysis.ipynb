{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in /opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages (0.3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Loading the required libraries\n",
    "%pip install nbimporter\n",
    "import nbimporter\n",
    "import feature_extraction\n",
    "from feature_extraction import EmpathFeatureExtractor\n",
    "from feature_extraction import NGramFeatureExtractor\n",
    "from feature_extraction import EmpathFeatureAnalyzer\n",
    "from feature_extraction import LDAFeatureExtractor\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%store -r selected_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1878 documents.\n",
      "Labels: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "# Load documents and labels\n",
    "folders = {\n",
    "    \"depression\": {\"path\": \"data/preprocessed_posts/depression\", \"label\": 1},\n",
    "    \"breastcancer\": {\"path\": \"data/preprocessed_posts/breastcancer\", \"label\": 0},\n",
    "}\n",
    "documents, labels = [], []\n",
    "for category, data in folders.items():\n",
    "    for file_name in os.listdir(data[\"path\"]):\n",
    "        file_path = os.path.join(data[\"path\"], file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            documents.append(file.read())\n",
    "            labels.append(data[\"label\"])\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(f\"Labels: {set(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an LDAFeatureAnalyzer object\n",
    "\n",
    "class LDAFeatureAnalyzer:\n",
    "    def __init__(self, lda_model, corpus, topic_matrix, dictionary, labels, num_topics):\n",
    "        \"\"\"\n",
    "        Initialize the LDAFeatureAnalyzer class.\n",
    "\n",
    "        Parameters:\n",
    "        lda_model: Trained Gensim LDA model.\n",
    "        corpus: The Bag-of-Words corpus used for LDA.\n",
    "        topic_matrix: Document-topic matrix (output of topic_distribution_to_matrix).\n",
    "        dictionary: Gensim Dictionary object used in LDA training.\n",
    "        labels: Labels corresponding to the documents.\n",
    "        num_topics: Number of topics in the LDA model.\n",
    "        \"\"\"\n",
    "        self.lda_model = lda_model\n",
    "        self.corpus = corpus\n",
    "        self.topic_matrix = topic_matrix\n",
    "        self.dictionary = dictionary\n",
    "        self.labels = labels\n",
    "        self.num_topics = num_topics\n",
    "\n",
    "    def get_top_words_per_topic(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Get the top N words for each topic in the LDA model.\n",
    "\n",
    "        Parameters:\n",
    "        top_n (int): Number of top words to return for each topic.\n",
    "\n",
    "        Returns:\n",
    "        A dictionary where keys are topic IDs and values are lists of top N words.\n",
    "        \"\"\"\n",
    "        top_words = {}\n",
    "        for topic_id in range(self.num_topics):\n",
    "            top_words[topic_id] = [\n",
    "                word for word, _ in self.lda_model.show_topic(topic_id, topn=top_n)\n",
    "            ]\n",
    "        return top_words\n",
    "\n",
    "    def generate_wordclouds(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Generate word clouds for each topic.\n",
    "\n",
    "        Parameters:\n",
    "        top_n (int): Number of top words to include in the word cloud.\n",
    "        \"\"\"\n",
    "        top_words = self.get_top_words_per_topic(top_n=top_n)\n",
    "        for topic_id, words in top_words.items():\n",
    "            word_freqs = {word: weight for word, weight in self.lda_model.show_topic(topic_id, topn=top_n)}\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freqs)\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"Topic {topic_id} Word Cloud\")\n",
    "            plt.show()\n",
    "\n",
    "    def perform_tsne(self, perplexity=50, n_iter=500):\n",
    "        \"\"\"\n",
    "        Perform t-SNE to reduce topic matrix to 2D for visualization.\n",
    "\n",
    "        Parameters:\n",
    "        perplexity (int): Perplexity parameter for t-SNE.\n",
    "        n_iter (int): Number of iterations for t-SNE.\n",
    "\n",
    "        Returns:\n",
    "        tsne_results: A 2D array of t-SNE coordinates for visualization.\n",
    "        \"\"\"\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)\n",
    "        tsne_results = tsne.fit_transform(self.topic_matrix)\n",
    "        return tsne_results\n",
    "\n",
    "    def visualize_tsne(self, tsne_results):\n",
    "        \"\"\"\n",
    "        Visualize the t-SNE results as a scatter plot.\n",
    "\n",
    "        Parameters:\n",
    "        tsne_results: A 2D array of t-SNE coordinates for visualization.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        scatter = plt.scatter(\n",
    "            tsne_results[:, 0],\n",
    "            tsne_results[:, 1],\n",
    "            c=self.labels,\n",
    "            cmap='viridis',\n",
    "            s=10,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.colorbar(scatter, label=\"Labels\")\n",
    "        plt.title(\"t-SNE Visualization of LDA Topic Distributions\")\n",
    "        plt.xlabel(\"t-SNE Dimension 1\")\n",
    "        plt.ylabel(\"t-SNE Dimension 2\")\n",
    "        plt.show()\n",
    "\n",
    "    def generate_topics_summary(self, top_n=10):\n",
    "        \"\"\"\n",
    "        Generate a summary table of topics, showing top N words per topic.\n",
    "\n",
    "        Parameters:\n",
    "        top_n (int): Number of top words to include in the summary.\n",
    "\n",
    "        Returns:\n",
    "        A pandas DataFrame summarizing topics and their top N words.\n",
    "        \"\"\"\n",
    "        topic_summaries = []\n",
    "        for topic_id in range(self.num_topics):\n",
    "            top_words = \", \".join([word for word, _ in self.lda_model.show_topic(topic_id, topn=top_n)])\n",
    "            topic_summaries.append({\n",
    "                \"Topic ID\": topic_id,\n",
    "                \"Top Words\": top_words\n",
    "            })\n",
    "        return pd.DataFrame(topic_summaries)\n",
    "\n",
    "    def run_analysis(self):\n",
    "        \"\"\"\n",
    "        Run the complete analysis pipeline: generate word clouds, perform t-SNE, and print topic summary.\n",
    "        \"\"\"\n",
    "        print(\"Generating Word Clouds...\")\n",
    "        self.generate_wordclouds()\n",
    "\n",
    "        print(\"Performing t-SNE...\")\n",
    "        tsne_results = self.perform_tsne()\n",
    "        self.visualize_tsne(tsne_results)\n",
    "\n",
    "        print(\"Generating Topic Summary Table...\")\n",
    "        summary_df = self.generate_topics_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency and Predictive Power of N-gram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting n-gram features\n",
    "ngram_extractor = NGramFeatureExtractor(documents, labels)\n",
    "ngram_extractor.extract_features()\n",
    "depression_unigram_freqs, non_depression_unigram_freqs = ngram_extractor.compute_frequencies(feature_type=\"unigram\")\n",
    "depression_bigram_freqs, non_depression_bigram_freqs = ngram_extractor.compute_frequencies(feature_type=\"bigram\")\n",
    "top_100_depression_unigrams = ngram_extractor.get_top_n_features(depression_unigram_freqs, top_n=100)\n",
    "print(top_100_depression_unigrams)\n",
    "top_100_non_depression_unigrams = ngram_extractor.get_top_n_features(non_depression_unigram_freqs, top_n=100)\n",
    "print(top_100_non_depression_unigrams)\n",
    "top_100_depression_bigrams = ngram_extractor.get_top_n_features(depression_bigram_freqs, top_n=100)\n",
    "print(top_100_depression_bigrams)\n",
    "top_100_non_depression_bigrams = ngram_extractor.get_top_n_features(non_depression_bigram_freqs, top_n=100)\n",
    "print(top_100_non_depression_bigrams)\n",
    "ngram_extractor.visualize_wordcloud(depression_unigram_freqs, \"Depression Unigram Word Cloud\")\n",
    "ngram_extractor.visualize_wordcloud(non_depression_unigram_freqs, \"Non-Depression Unigram Word Cloud\")\n",
    "ngram_extractor.visualize_wordcloud(depression_bigram_freqs, \"Depression Bigram Word Cloud\")\n",
    "ngram_extractor.visualize_wordcloud(non_depression_bigram_freqs, \"Non-Depression Bigram Word Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Power of Empath Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Empath features with shape: (293, 237)\n",
      "Removed constant columns: ['articles', 'auxiliary_verbs', 'adverbs', 'conjunctions', 'personal_pronouns', 'impersonal_pronouns', 'negations', 'prepositions', 'verbs', 'nouns', 'adjectives', 'comparatives', 'superlatives', 'modifiers', 'function_words', 'filler_words', 'verb_tense', 'slang', 'jargon', 'formal_language', 'casual_language', 'exclamations', 'contractions', 'word_complexity', 'sentiment_words', 'anxiety', 'hope', 'excitement', 'relief', 'gratitude', 'guilt', 'boredom', 'embarrassment', 'longing', 'nostalgia', 'frustration', 'melancholy', 'illness', 'fitness', 'nutrition', 'ingestion', 'physical_state', 'medicine', 'aging', 'disease', 'hospital', 'recovery', 'dieting', 'mental_health', 'drug_use', 'headache', 'fatigue', 'hormones', 'appetite', 'relationships', 'group_behavior', 'teamwork', 'community', 'peer_pressure', 'leadership', 'parenting', 'mentorship', 'marriage', 'divorce', 'gender_roles', 'social_identity', 'cultural_rituals', 'networking', 'altruism', 'conflict', 'social_support', 'dominance', 'affiliation', 'intimacy', 'supportiveness', 'competition', 'conflict_resolution', 'collaboration', 'in-group', 'out-group', 'prejudice', 'certainty', 'doubt', 'insight', 'cause', 'discrepancy', 'problem_solving', 'creativity', 'self_reflection', 'planning', 'memory', 'perception', 'attention', 'reasoning', 'thought_process', 'decision_making', 'learning', 'metacognition', 'adaptability', 'focus', 'perspective', 'problem_analysis', 'evaluation', 'interpretation', 'logic', 'intelligence', 'rational_thought', 'intuition', 'conceptualization', 'control', 'self-esteem', 'autonomy', 'self-assertion', 'ambition', 'conformity', 'subordination', 'dependence', 'submission', 'accomplishment', 'control_seeking', 'status', 'prosocial_behavior', 'spirituality', 'faith', 'beliefs', 'sacred', 'prayer', 'meditation', 'afterlife', 'soul', 'god', 'higher_power', 'inspiration', 'transcendence', 'morality', 'ethics', 'rituals', 'holiness', 'mindfulness', 'wealth', 'career', 'travel', 'education', 'retirement', 'family_life', 'hobbies', 'volunteering', 'pets', 'entertainment', 'adventure', 'environment', 'safety', 'materialism', 'self_improvement', 'self_growth', 'happiness', 'life_purpose', 'work_life_balance', 'stress', 'coping', 'job_satisfaction', 'legacy', 'job_search', 'unemployment', 'retirement_plans', 'dating', 'romantic_relationships', 'life_stressors', 'transitions', 'present', 'past', 'future', 'afternoon', 'evening', 'day', 'weekdays', 'weekends', 'seasons', 'holidays', 'lifespan', 'long_term', 'short_term', 'routine', 'historical', 'epoch', 'momentary', 'timeliness', 'timelessness', 'urgency', 'progression']\n",
      "                       LIWC Category Example Word Correlation P-Value\n",
      " psychological_processes - affective  contentment        0.17   0.000\n",
      "                   personal_concerns     violence        0.16   0.000\n",
      "psychological_processes - biological         pain        0.13   0.000\n",
      "    psychological_processes - social      friends        0.14   0.000\n",
      "                   time_orientations      morning        0.14   0.006\n",
      " psychological_processes - spiritual     religion        0.11   0.031\n",
      "    psychological_processes - drives        power        0.09   0.043\n",
      " psychological_processes - cognitive    confusion        0.00   0.943\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the Empath model\n",
    "empath_analyzer = EmpathFeatureAnalyzer(documents, labels, selected_categories)\n",
    "\n",
    "# Run the pipeline\n",
    "empath_analyzer.extract_empath_features()\n",
    "empath_analyzer.analyze_correlation()\n",
    "empath_analyzer.group_correlations_by_subcategory()\n",
    "\n",
    "# Generate and visualize the summary table\n",
    "summary_table = empath_analyzer.generate_summary_table()\n",
    "empath_analyzer.visualize_summary_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Predictive Power of LDA Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Use Latent Dirichlet Allocation (LDA) to discover hidden topics in the posts, identifying themes associated with depression.\n",
    "\n",
    "Process:\n",
    "Train LDA models on the text data.\n",
    "Generate topic distributions for each post (probability of belonging to each topic).\n",
    "Select the top 20 topics with the largest proportions in the data.\n",
    "Use t-SNE for dimensionality reduction to visualize topic clusters in 2D space.\n",
    "\n",
    "Findings:\n",
    "Topics indicative of depression include:\n",
    "Themes like \"Depression,\" \"Broke,\" \"Tired,\" \"Pain,\" reflecting suffering, self-preoccupation, and low self-esteem.\n",
    "Words associated with disclosure, loneliness, hostility, and interpersonal issues.\n",
    "\n",
    "Significance: LDA captures latent patterns that are not explicitly defined (unlike LIWC), enabling nuanced analysis of depression-related themes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_extractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assume the following are already generated from LDAFeatureExtractor:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mlda_extractor\u001b[49m\u001b[38;5;241m.\u001b[39mlda_model\n\u001b[1;32m      3\u001b[0m corpus \u001b[38;5;241m=\u001b[39m lda_extractor\u001b[38;5;241m.\u001b[39mcorpus\n\u001b[1;32m      4\u001b[0m topic_matrix \u001b[38;5;241m=\u001b[39m lda_extractor\u001b[38;5;241m.\u001b[39mtopic_distribution_to_matrix()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_extractor' is not defined"
     ]
    }
   ],
   "source": [
    "# Assume the following are already generated from LDAFeatureExtractor:\n",
    "lda_model = lda_extractor.lda_model\n",
    "corpus = lda_extractor.corpus\n",
    "topic_matrix = lda_extractor.topic_distribution_to_matrix()\n",
    "dictionary = lda_extractor.dictionary\n",
    "labels = labels  # Labels from your dataset\n",
    "num_topics = lda_extractor.num_topics\n",
    "\n",
    "# Initialize the analyzer\n",
    "lda_analyzer = LDAFeatureAnalyzer(lda_model, corpus, topic_matrix, dictionary, labels, num_topics)\n",
    "\n",
    "# Run analysis\n",
    "lda_summary = lda_analyzer.run_analysis()\n",
    "\n",
    "# Save the topic summary table if needed\n",
    "lda_summary.to_csv(\"lda_topics_summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
