{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the preprocessed data as 'posts' and 'labels' to be used also\n",
    "\n",
    "posts = []  \n",
    "labels = [] \n",
    "\n",
    "folders = {\n",
    "    \"depression\": {\n",
    "        \"path\": \"data/preprocessed/preprocessed_depression_posts\",\n",
    "        \"label\": 1  # Label for depression-related posts\n",
    "    },\n",
    "    \"breastcancer\": {\n",
    "        \"path\": \"data/preprocessed/preprocessed_breastcancer_posts\",\n",
    "        \"label\": 0  # Label for breast cancer posts\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, data in folders.items():\n",
    "    folder_path = data[\"path\"]\n",
    "    label = data[\"label\"]\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()  # Read the file content\n",
    "                posts.append(content)  # Add to postst list\n",
    "                labels.append(label)  # Add corresponding label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: SVM (x6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on unigram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on unigram data\n",
    "\n",
    "# Load the unigram features and labels\n",
    "unigram_data_file = \"data/feature_extracted_data/unigram_features_with_labels.csv\"  # Update path if needed\n",
    "unigram_df = pd.read_csv(unigram_data_file)\n",
    "\n",
    "# Separate features and labels\n",
    "X = unigram_df.iloc[:, :-1].values  # All columns except the last one are features\n",
    "y = unigram_df.iloc[:, -1].values  # The last column is the label\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)  # Use a linear kernel for interpretability\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the unigram feature distribution using t-SNE\n",
    "\n",
    "# Reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_test_tsne = tsne.fit_transform(X_test)  # Apply t-SNE to test data\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_test_tsne[:, 0], X_test_tsne[:, 1], c=y_test, cmap='viridis', s=15, alpha=0.8)\n",
    "plt.title(\"t-SNE Visualization of Unigram Features (Test Data)\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "\n",
    "# Add legend for the labels\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=[\"Non-Depressed\", \"Depressed\"], title=\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which words are most important for the SVM model\n",
    "\n",
    "# Get the coefficients and feature names\n",
    "coefficients = svm_model.coef_.flatten()  # Coefficients for each feature\n",
    "unigram_features = unigram_df.columns[:-1]  # Feature names (all except the last column)\n",
    "\n",
    "# Create a DataFrame to pair unigrams with their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Unigram\": unigram_features,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Sort by coefficient values (absolute values indicate importance)\n",
    "coef_df_sorted = coef_df.reindex(coef_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Print top unigrams for depression (positive coefficients) and non-depression (negative coefficients)\n",
    "print(\"Top Unigrams Associated with Depression:\")\n",
    "print(coef_df_sorted[coef_df_sorted[\"Coefficient\"] > 0].head(10))\n",
    "\n",
    "print(\"\\nTop Unigrams Associated with Non-Depression:\")\n",
    "print(coef_df_sorted[coef_df_sorted[\"Coefficient\"] < 0].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on bigram data\n",
    "# Load the dataset\n",
    "bigram_data_file = \"data/feature_extracted_data/bigram_features_with_labels.csv\"  # Adjust path if necessary\n",
    "bigram_df = pd.read_csv(bigram_data_file)\n",
    "\n",
    "# Separate features and labels\n",
    "X = bigram_df.iloc[:, :-1].values  # All columns except the last one (features)\n",
    "y = bigram_df['label'].values     # The last column contains the labels\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the bigram feature distribution using t-SNE\n",
    "\n",
    "# Reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_test_tsne = tsne.fit_transform(X_test)  # Apply t-SNE to test data\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_test_tsne[:, 0], X_test_tsne[:, 1], c=y_test, cmap='viridis', s=15, alpha=0.8)\n",
    "plt.title(\"t-SNE Visualization of Bigram Features (Test Data)\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "\n",
    "# Add legend for the labels\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=[\"Non-Depressed\", \"Depressed\"], title=\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which bigrams are most important for the SVM model\n",
    "# Get the coefficients and feature names\n",
    "coefficients = svm_model.coef_.flatten()  # Coefficients for each feature\n",
    "bigram_features = bigram_df.columns[:-1]  # Feature names (all except the last column)\n",
    "\n",
    "# Create a DataFrame to pair unigrams with their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Unigram\": bigram_features,\n",
    "    \"Coefficient\": coefficients\n",
    "})\n",
    "\n",
    "# Sort by coefficient values (absolute values indicate importance)\n",
    "coef_df_sorted = coef_df.reindex(coef_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Print top unigrams for depression (positive coefficients) and non-depression (negative coefficients)\n",
    "print(\"Top Bigrams Associated with Depression:\")\n",
    "print(coef_df_sorted[coef_df_sorted[\"Coefficient\"] > 0].head(10))\n",
    "\n",
    "print(\"\\nTop Bigrams Associated with Non-Depression:\")\n",
    "print(coef_df_sorted[coef_df_sorted[\"Coefficient\"] < 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MLP (x6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regriession model class\n",
    "class LinearRegressionModel:\n",
    "    def __init__(self, csv_files, model_name, random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize the LinearRegressionModel class.\n",
    "\n",
    "        Parameters:\n",
    "        csv_files (list of str): List of file paths for the feature datasets (CSV files).\n",
    "        model_name (str): Name of the model for identification.\n",
    "        \"\"\"\n",
    "        self.csv_files = csv_files\n",
    "        self.model_name = model_name\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def load_and_combine_data(self):\n",
    "        \"\"\"\n",
    "        Load and combine data from multiple CSV files into a single dataset.\n",
    "        Assumes each CSV has the same 'label' column.\n",
    "        \"\"\"\n",
    "        print(f\"Loading data for {self.model_name}...\")\n",
    "        data_frames = [pd.read_csv(file) for file in self.csv_files]\n",
    "    \n",
    "        # Ensure labels are consistent and take from the first dataset\n",
    "        labels = data_frames[0]['label']\n",
    "        for df in data_frames[1:]:\n",
    "            if 'label' in df.columns:\n",
    "                df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "        combined_data = pd.concat(data_frames, axis=1)\n",
    "\n",
    "        # Check alignment between features and labels\n",
    "        if len(labels) != len(combined_data):\n",
    "            raise ValueError(\n",
    "                f\"Mismatch between features and labels: \"\n",
    "                f\"{len(combined_data)} rows in features, {len(labels)} in labels.\"\n",
    "            )\n",
    "\n",
    "        # Add the label column\n",
    "        self.data = combined_data\n",
    "        self.data['label'] = labels\n",
    "        print(f\"Loaded data shape: {self.data.shape}\")\n",
    "\n",
    "    def preprocess_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Split the data into training and testing sets.\n",
    "\n",
    "        Parameters:\n",
    "        test_size (float): Proportion of data to use for testing.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        print(\"Splitting data into train and test sets...\")\n",
    "        X = self.data.iloc[:, :-1]  # All columns except the label column\n",
    "        y = self.data['label']  # Label column\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state\n",
    "        )\n",
    "        print(f\"Training set size: {self.X_train.shape}, Test set size: {self.X_test.shape}\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Train a Logistic Regression model on the training data.\n",
    "        \"\"\"\n",
    "        print(f\"Training {self.model_name}...\")\n",
    "        self.model = LogisticRegression(max_iter=500)\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        print(f\"Model {self.model_name} trained successfully.\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate the trained model on the test data and print metrics.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(f\"Model {self.model_name} has not been trained yet.\")\n",
    "        \n",
    "        print(f\"Evaluating {self.model_name}...\")\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred))\n",
    "        print(f\"Accuracy: {accuracy_score(self.y_test, y_pred)}\")\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Complete pipeline: load data, preprocess, train, and evaluate.\n",
    "        \"\"\"\n",
    "        self.load_and_combine_data()\n",
    "        self.preprocess_data()\n",
    "        self.train_model()\n",
    "        self.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the feature extraction data\n",
    "empath_file = \"data/feature_extracted_data/empath_features_with_labels.csv\"\n",
    "lda_file = \"data/feature_extracted_data/lda_topic_distributions_with_labels.csv\"\n",
    "unigram_file = \"data/feature_extracted_data/unigram_features_with_labels.csv\"\n",
    "bigram_file = \"data/feature_extracted_data/bigram_features_with_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (Empath)\n",
    "lr_em = LinearRegressionModel([empath_file], \"LR (Em)\")\n",
    "lr_em.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (LDA)\n",
    "lr_lda = LinearRegressionModel([lda_file], \"LR (LDA)\")\n",
    "lr_lda.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (unigram)\n",
    "lr_unigram = LinearRegressionModel([unigram_file], \"LR (Unigram)\")\n",
    "lr_unigram.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (bigram)\n",
    "lr_bigram = LinearRegressionModel([bigram_file], \"LR (Bigram)\")\n",
    "lr_bigram.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (EM + LDA + unigram)\n",
    "lr_em_lda_unigram = LinearRegressionModel([empath_file, lda_file, unigram_file], \"LR (EM + LDA + Unigram)\")\n",
    "lr_em_lda_unigram.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR (EM + LDA + bigram)\n",
    "lr_em_lda_bigram = LinearRegressionModel([empath_file, lda_file, bigram_file], \"LR (EM + LDA + Bigram)\")\n",
    "lr_em_lda_bigram.run_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: RF (x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on unigram data\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the RF model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the RF model\n",
    "print(\"Random Forest Accuracy (Unigram):\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest Classification Report (Unigram):\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on bigram data\n",
    "\n",
    "# Train a Random Forest model on bigram data\n",
    "rf_model_bigram = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model_bigram.fit(X_train_bigram, y_train_bigram)\n",
    "\n",
    "# Make predictions using the RF model on bigram data\n",
    "y_pred_rf_bigram = rf_model_bigram.predict(X_test_bigram)\n",
    "\n",
    "# Evaluate the RF model on bigram data\n",
    "print(\"Random Forest Accuracy (Bigram):\", accuracy_score(y_test_bigram, y_pred_rf_bigram))\n",
    "print(\"\\nRandom Forest Classification Report (Bigram):\\n\", classification_report(y_test_bigram, y_pred_rf_bigram))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: ADA (x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost on unigram data\n",
    "\n",
    "# Train an AdaBoost model\n",
    "ada_model = AdaBoostClassifier(random_state=42, n_estimators=50)\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the ADA model\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ADA model\n",
    "print(\"AdaBoost Accuracy (Unigram):\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"\\nAdaBoost Classification Report (Unigram):\\n\", classification_report(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost on bigram data\n",
    "\n",
    "# Train an AdaBoost model on bigram data\n",
    "ada_model_bigram = AdaBoostClassifier(random_state=42, n_estimators=50)\n",
    "ada_model_bigram.fit(X_train_bigram, y_train_bigram)\n",
    "\n",
    "# Make predictions using the ADA model on bigram data\n",
    "y_pred_ada_bigram = ada_model_bigram.predict(X_test_bigram)\n",
    "\n",
    "# Evaluate the ADA model on bigram data\n",
    "print(\"AdaBoost Accuracy (Bigram):\", accuracy_score(y_test_bigram, y_pred_ada_bigram))\n",
    "print(\"\\nAdaBoost Classification Report (Bigram):\\n\", classification_report(y_test_bigram, y_pred_ada_bigram))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
